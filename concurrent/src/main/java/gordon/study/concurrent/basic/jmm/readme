###### 基础理论摘要：
https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html

## 同步 Synchronization
Java有多种线程间通信机制，最基础的方法是同步。（PS：个人理解线程间通信机制有共享内存机制和消息通信机制，同步是一种共享内存方式）。
Java同步用监视器（monitor）实现。每个 object 关联到一个 monitor，线程可以对这个 monitor 加锁或解锁。任一时刻只有一个线程可以持有 monitor 上的锁。
其它尝试获取该 monitor 锁的线程会被阻塞，直到能够获得锁。线程可以对指定 monitor 多次加锁，每次解锁操作只能解一把锁。

synchronized 语句、synchronized 方法、volatile 变量、java.util.concurrent 包中的类提供了不同的同步方式。

## Wait Sets and Notification
每个对象除了关联一个 monitor，还关联一个 wait set。wait set 中存放的是线程。将线程放入或移出 wait set 的操作是原子操作。
wait sets 只被 Object.wait、Object.notify 和 Object.notifyAll 方法操作！
（PS：前文说尝试获取 monitor 锁的线程会被阻塞，那应该有个 set 用来存放这些被阻塞的线程喽？不会是队列因为 synchronized 不保证排队顺序。Object.notify
是不是将某个线程从 wait sets 取出，放到阻塞 set，这样可以解决 notify 调用不是同步块最后一条指令的问题）

## Sleep and Yield
Thread.sleep 与 Thread.yield 都不具有同步语义。（都不会释放锁）

## Memory Model
见下文 JMM 中文学习资料



###### 内存模型
https://blog.csdn.net/Primitive_Heart/article/details/85088018

内存模型是对内存进行读写访问过程的抽象。也可以这样说，内存模型定义正确的内存读写行为(单线程)。

什么是内存模型：为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。（摘自网络）

## 顺序一致性内存模型
禁止编译器优化：按(单线程)程序的顺序依次访问内存。
禁止处理器优化：每个写的操作是立即可见的通过内存。

## 处理器内存模型
TSO内存模型（一种处理器内存模型）是在顺序一致性内存模型基础上放松对写读操作顺序(重排序)而产生的一种内存模型。（由于现代处理器都使用写缓冲区，
因此现代处理器都允许对写读操作进行重排序）

## Java内存模型
描述一组规则或是规范，这个定义了一个线程对共享变量的写入何时对另一个线程可见。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。

正确同步Java内存模型的多线程跟顺序一致性的内存模型的执行路径是一致的

Java的内存模型是对程序员是透明的，Java内存模型是以 happens-before 方式呈现给程序员的：
后一个语句执行需要依赖前一个语句的执行结果，且前一个语句按顺序排在后一个语句的前面。

它保证内存一致性，对程序员是透明的，它是通过解决重排序问题来保证的。
它能禁止某种特定类型的编译器重排序
它能禁止某种特定类型的处理器重排序
通过内存屏障来禁止处理器重排序。在生成最终指令的序列过程中插入内存屏障(在使用同步原语(lock,volatile等)适当的位置插入)。
并不是对所有的处理器重排序都禁止，它只是禁止某种特定类型的重排序。



###### JMM 中文学习资料：
https://www.infoq.cn/profile/1278512

在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。
同步是指程序用于控制不同线程之间操作发生相对顺序的机制。
Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。

Java线程之间的通信由Java内存模型（JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的
抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量
的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。

## 重排序
为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：
1. 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
2. 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器
可以改变语句对应机器指令的执行顺序。
3. 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。
上述的1属于编译器重排序，2和3属于处理器重排序。

对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序。对于处理器重排序，JMM的处理器重排序规则会要求java编译器在生成指令序列时，插入特定
类型的内存屏障（memory barriers，intel称之为memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。为程序员提供一致的内存可见性保证。

## happens-before
Java使用happens-before的概念来阐述操作之间的内存可见性。
在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，
也可以是在不同线程之间。

与程序员密切相关的happens-before规则如下：
   程序顺序规则：一个线程中的每个操作，happens-before 于该线程中的任意后续操作。
   监视器锁规则：对一个监视器锁的解锁，happens-before 于随后对这个监视器锁的加锁。
   volatile变量规则：对一个volatile域的写，happens-before 于任意后续对这个volatile域的读。
   传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。

## volatile
前置知识：某些32位的处理器会把一个64位 long/double 型变量的读/写操作拆分为两个32位的读/写操作来执行。这两个32位的读/写操作可能会被分配到不同的
总线事务中执行，此时对这个64位变量的读/写将不具有原子性。

理解volatile特性的一个好方法是：把对volatile变量的单个读/写，看成是使用同一个监视器锁对这些单个读/写操作做了同步。

volatile变量自身具有下列特性：
  可见性：对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。
  原子性：对任意单个volatile变量的读/写具有原子性，但类似于 volatile++ 这种复合操作不具有原子性。
（PS：就像ConcurrentHashMap的put和contains都是线程安全的，但是组合使用判断不存在则放入不是线程安全的，必须用putIfAbsent）

volatile变量的写-读可以实现线程之间的通信。从内存语义的角度来说，volatile与监视器锁有相同的效果：volatile 写和监视器的释放有相同的内存语义；
volatile读与监视器的获取有相同的内存语义。

volatile写的内存语义：当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存。
volatile读的内存语义：当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。

volatile写和volatile读的内存语义总结：
线程 A 写一个 volatile 变量，实质上是线程 A 向接下来将要读这个 volatile 变量的某个线程发出了（其对共享变量所在修改的）消息。
线程 B 读一个 volatile 变量，实质上是线程 B 接收了之前某个线程发出的（在写这个 volatile 变量之前对共享变量所做修改的）消息。
线程 A 写一个 volatile 变量，随后线程 B 读这个 volatile 变量，这个过程实质上是线程 A 通过主内存向线程 B 发送消息。
（PS：想象线程B在轮询查询该变量值）

volatile 内存语义的实现：
volatile 写之前的操作不会被编译器重排序到 volatile 写之后。
volatile 读之后的操作不会被编译器重排序到 volatile 读之前。
当第一个操作是 volatile 写，第二个操作是 volatile 读时，不能重排序。

基于保守策略的 JMM 内存屏障插入策略：
在每个 volatile 写操作的前面插入一个 StoreStore 屏障。
在每个 volatile 写操作的后面插入一个 StoreLoad 屏障。
在每个 volatile 读操作的后面插入一个 LoadLoad 屏障。
在每个 volatile 读操作的后面插入一个 LoadStore 屏障。

## 锁
锁是 java 并发编程中最重要的同步机制。锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。

当线程释放锁时，JMM 会把该线程对应的本地内存中的共享变量刷新到主内存中。
当线程获取锁时，JMM 会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须要从主内存中去读取共享变量。

锁释放和锁获取的内存语义总结：
线程 A 释放一个锁，实质上是线程 A 向接下来将要获取这个锁的某个线程发出了（线程 A 对共享变量所做修改的）消息。
线程 B 获取一个锁，实质上是线程 B 接收了之前某个线程发出的（在释放这个锁之前对共享变量所做修改的）消息。
线程 A 释放锁，随后线程 B 获取这个锁，这个过程实质上是线程 A 通过主内存向线程 B 发送消息。

## final
重排序规则：
在构造函数内对一个 final 域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。
初次读一个包含 final 域的对象的引用，与随后初次读这个 final 域，这两个操作之间不能重排序。

写 final 域的重排序规则禁止把 final 域的写重排序到构造函数之外。这个规则的实现包含下面 2 个方面：
  JMM 禁止编译器把 final 域的写重排序到构造函数之外。
  编译器会在 final 域的写之后，构造函数 return 之前，插入一个 StoreStore 屏障。这个屏障禁止处理器把 final 域的写重排序到构造函数之外。

读 final 域的重排序规则如下：
  在一个线程中，初次读对象引用与初次读该对象包含的 final 域，JMM 禁止处理器重排序这两个操作（注意，这个规则仅仅针对处理器）。编译器会在读
    final 域操作的前面插入一个 LoadLoad 屏障。

## JMM的内存可见性保证
1. 单线程程序。单线程程序不会出现内存可见性问题。编译器，runtime和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。
2. 正确同步的多线程程序。正确同步的多线程程序的执行将具有顺序一致性（程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同）。
这是JMM关注的重点，JMM通过限制编译器和处理器的重排序来为程序员提供内存可见性保证。
3. 未同步/未正确同步的多线程程序。JMM为它们提供了最小安全性保障：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，null，false）。
（疑问：部分32位机器对long/double类型做不到吧？）



###### 双重检查锁定与延迟初始化：
https://www.infoq.cn/article/double-checked-locking-with-delay-initialization












